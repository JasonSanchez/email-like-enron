{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing get_books.sh\n"
     ]
    }
   ],
   "source": [
    "%%file get_books.sh\n",
    "#!/usr/bin/bash\n",
    "!wget -nd -r -l 10 -A.txt ftp://ftp.ibiblio.org/pub/docs/books/gutenberg/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing books.avsc\n"
     ]
    }
   ],
   "source": [
    "%%file books.avsc\n",
    "{\"namespace\": \"book_data.avro\",\n",
    " \"type\": \"record\",\n",
    " \"name\": \"txt\",\n",
    " \"fields\": [\n",
    "     {\"name\": \"title\", \"type\": \"string\"},\n",
    "     {\"name\": \"author\",  \"type\": [\"string\", \"null\"]},\n",
    "     {\"name\": \"contents\", \"type\": [\"string\", \"null\"]},\n",
    "     {\"name\": \"part\",  \"type\": \"int\"},\n",
    "     {\"name\": \"hash\", \"type\": [\"string\", \"null\"]}\n",
    " ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting books.py\n"
     ]
    }
   ],
   "source": [
    "# %%file books.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import glob\n",
    "from hashlib import md5\n",
    "import avro.schema\n",
    "from avro.datafile import DataFileWriter\n",
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumWriter\n",
    "from avro.io import DatumReader\n",
    "\n",
    "def is_not_digit(path):\n",
    "    just_name = path.split(\"/\")[-1].split(\".\")[0]\n",
    "    return not just_name.isdigit()\n",
    "\n",
    "def not_good_file(path):\n",
    "    return \"-\" in path or is_not_digit(path)\n",
    "\n",
    "def md5_hash(k):\n",
    "    return md5(k.encode()).hexdigest()\n",
    "\n",
    "def get_text(path):\n",
    "    with open(path) as book:\n",
    "        return book.read()\n",
    "\n",
    "def extract_term(term_indicator, text, default=None, max_term_size=75):\n",
    "    term_start = text.find(term_indicator)\n",
    "    # If not found, \n",
    "    if term_start == -1:\n",
    "        term = default\n",
    "    else:\n",
    "        term_end = text.find(\"\\n\", term_start)\n",
    "        term = text[term_start+len(term_indicator):term_end].strip()\n",
    "    if term and (len(term) > max_term_size):\n",
    "        term = default\n",
    "    return term\n",
    "\n",
    "def get_author_and_title(book_text):\n",
    "    title = extract_term(\"Title:\", book_text, default=None)\n",
    "    author = extract_term(\"Author:\", book_text, default=None)\n",
    "    # Solve  for other strange author name formatting\n",
    "    for term_indicator in [\"\\n\\nby \", \"\\n\\nOF \", \"\\nOF\\n\"]:\n",
    "        if author is None:\n",
    "            author = extract_term(term_indicator, book_text[:15000], max_term_size=25)\n",
    "    return title, author\n",
    "\n",
    "def locate_beginning_of_text(title, author, text):\n",
    "    if title:\n",
    "        location = text.find(title)\n",
    "    if author:\n",
    "        location = text.find(author)\n",
    "    return location\n",
    "\n",
    "def parse_book(book_text):\n",
    "    \"\"\"\n",
    "    Given the text of a book, returns a list of dictionaries with the keys:\n",
    "    {title, author, contents, part, hash}\n",
    "    \"\"\"\n",
    "    parsed_book_paragraphs = []\n",
    "    title, author = get_author_and_title(book_text)\n",
    "    if title or author:\n",
    "        # Get start of text position\n",
    "        text_starts = locate_beginning_of_text(title, author, book_text)\n",
    "        book_paragraphs = book_text[text_starts:].split(\"\\n\\n\")\n",
    "        for paragraph_number, raw_paragraph in enumerate(book_paragraphs):\n",
    "            paragraph = raw_paragraph.replace(\"\\n\", \" \").strip()\n",
    "            book_data = {\"title\": title,\n",
    "                         \"author\": author,\n",
    "                         \"contents\": paragraph,\n",
    "                         \"part\": paragraph_number,\n",
    "                         \"hash\": md5_hash(paragraph)}\n",
    "            parsed_book_paragraphs.append(book_data)\n",
    "    return parsed_book_paragraphs            \n",
    "\n",
    "def write_to_avro(book_paragraph_data, schema_location=\"books.avsc\", output_location=\"book_data.avro\"):\n",
    "    \"\"\"\n",
    "    Write book paragraphs to some output location based on a defined schema.\n",
    "    \"\"\"\n",
    "    schema = avro.schema.parse(open(schema_location).read())\n",
    "    with DataFileWriter(open(output_location, \"w\"), DatumWriter(), schema) as writer:\n",
    "        for paragraph in book_paragraph_data:\n",
    "            writer.append(paragraph)\n",
    "\n",
    "\n",
    "BOOK_DIRECTORY = \"books\"\n",
    "# TODO: add this schema\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    paragraphs = []\n",
    "\n",
    "    for filename in list(glob.iglob(BOOK_DIRECTORY + '/*.txt')):\n",
    "        path = filename.replace(\"\\\\\", \"/\")\n",
    "\n",
    "        # Skip files that are not books\n",
    "        if not_good_file(path): continue\n",
    "\n",
    "        # Parse book.\n",
    "        book_text = get_text(path)\n",
    "        parsed_book = parse_book(book_text)\n",
    "        paragraphs.extend(parsed_book)\n",
    "        \n",
    "    # Write to avro\n",
    "    write_to_avro(paragraphs)\n",
    "    \n",
    "    # Code to read from avro\n",
    "    READ_BACK = False\n",
    "    if READ_BACK:\n",
    "        output_location = \"book_data.avro\"\n",
    "        with DataFileReader(open(output_location, \"r\"), DatumReader()) as reader:\n",
    "            for paragraph in reader:\n",
    "                print paragraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
